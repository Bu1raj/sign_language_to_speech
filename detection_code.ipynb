{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20921a12-fb6d-4abc-a6fc-1e6a638f3220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "\n",
    "#tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Loading pipeline config and building a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(\"sign_language_detection_15k\\models\\my_ssd_mobilenet_v2_fpnlite_320x320\\pipeline.config\")\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(\"sign_language_detection_15k\\models\\my_ssd_mobilenet_v2_fpnlite_320x320\", 'ckpt-16')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d731ffb-3fdd-44b2-82f2-89f8af60a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dba16ed-eedf-437d-bb09-e75f54af6061",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap('sign_language_detection_15k\\\\annotations\\\\label_map.pbtxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "931f6eec-6387-4269-9418-357416403526",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "genai.configure(api_key=\"Enter your gemini API key here\")\n",
    "model = genai.GenerativeModel(\"gemini-pro\")\n",
    "chat = model.start_chat(history=[])\n",
    "l = []\n",
    "\n",
    "def get_gemini_response(question):\n",
    "  response = chat.send_message(question)\n",
    "  return response\n",
    "\n",
    "def hello():\n",
    "    l=[]\n",
    "    x = (get_gemini_response(\"this is sign language detection project, our model detects some signs and these are the detected signs - \" + ' '.join(unique_labels) + \". Generate a simple sentence out of these signs which the impaired person wishes to communicate\"))\n",
    "    s = ''\n",
    "    for i in x:\n",
    "        s +=(i.text)\n",
    "    l.append(s)\n",
    "    print(l)\n",
    "    return l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63295dd7-148e-4769-9ed4-239161793db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected label: Hello, Score: 0.9639967083930969\n",
      "Detected label: Yes, Score: 0.7143480777740479\n",
      "['Hello', 'Yes']\n",
      "['Hello, may I have a Yes?']\n",
      "Cleared\n",
      "Detected label: Yes, Score: 0.7390885949134827\n",
      "Detected label: Hello, Score: 0.9605106115341187\n",
      "Detected label: I Love You, Score: 0.8469918966293335\n",
      "Detected label: No, Score: 0.7297326326370239\n",
      "['Yes', 'Hello', 'I Love You', 'No']\n",
      "['Hello, I love you. Is that a yes or no?']\n",
      "Cleared\n"
     ]
    }
   ],
   "source": [
    "unique_labels = []\n",
    "\n",
    "while True: \n",
    "    ret, frame = cap.read()\n",
    "    image_np = np.array(frame)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.5,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    for i in range(min(5, detections['num_detections'])):\n",
    "        class_id = int(detections['detection_classes'][i]) + label_id_offset\n",
    "        score = detections['detection_scores'][i]\n",
    "        if score > 0.7:\n",
    "            label = category_index[class_id]['name']\n",
    "            # Exclude face label\n",
    "            if label != 'Face' and label not in unique_labels:\n",
    "                unique_labels.append(label)\n",
    "                print(f'Detected label: {label}, Score: {score}')\n",
    "                \n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('u'):\n",
    "        print(unique_labels)\n",
    "        hello()\n",
    "        unique_labels.clear()\n",
    "        print(\"Cleared\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8763f3b2-350b-4acb-9269-2dbe4ba6f423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be9de5-e5d8-445e-a039-822cb421d25d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe00aea-48be-49f9-92e9-69f01fbfff43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
